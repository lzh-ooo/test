# 🚀 MateConv 预训练优化版 - 快速启动指南

## 📁 文件清单

我已经为您创建了以下优化文件：

| 文件名 | 说明 | 用途 |
|--------|------|------|
| `optimized_data_processing.py` | 优化的数据处理脚本 | 数据清洗和预处理 |
| `optimized_pretrain.py` | 优化的训练框架 | 核心训练逻辑 |
| `optimized_inference.py` | 优化的推理框架 | 文本生成功能 |
| `train.py` | 训练启动脚本 | 启动训练 |
| `inference.py` | 推理启动脚本 | 启动推理 |
| `utils.py` | 工具函数 | 辅助功能 |
| `config.yaml` | 配置文件 | 统一配置管理 |
| `quick_start.py` | 快速启动演示 | 交互式演示 |
| `README_优化版使用说明.md` | 详细使用文档 | 完整说明 |
| `prompts_example.txt` | 批量提示示例 | 批量生成测试 |

---

## ⚡ 快速开始

### 方式一：命令行启动（推荐）

#### 1️⃣ 数据处理

```bash
python optimized_data_processing.py
```

#### 2️⃣ 模型训练

**使用配置文件（推荐）：**
```bash
python train.py --config config.yaml
```

**使用命令行参数：**
```bash
python train.py \
    --epochs 15 \
    --batch_size 32 \
    --learning_rate 3e-4 \
    --optimizer_type adamw \
    --lr_scheduler cosine \
    --use_ema \
    --early_stopping
```

**分布式训练（多GPU）：**
```bash
torchrun --nproc_per_node=2 train.py --config config.yaml --ddp
```

#### 3️⃣ 模型推理

**单次生成：**
```bash
python inference.py \
    --model_path out/pretrain_512.pth \
    --prompt "中国" \
    --temperature 0.8
```

**交互式对话：**
```bash
python inference.py \
    --model_path out/pretrain_512.pth \
    --interactive
```

**流式输出：**
```bash
python inference.py \
    --model_path out/pretrain_512.pth \
    --prompt "长江、" \
    --stream
```

**批量生成：**
```bash
python inference.py \
    --model_path out/pretrain_512.pth \
    --batch_file prompts_example.txt
```

---

### 方式二：交互式演示

```bash
python quick_start.py
```

这会打开一个交互式菜单，您可以选择要演示的功能。

---

### 方式三：Python API

#### 训练示例

```python
from optimized_pretrain import Trainer, TrainingConfig
from model.model import Transformer
from model.LMConfig import LMConfig
from model.dataset import PretrainDataset

# 创建配置
config = TrainingConfig(
    data_path="./dataset/pretrain_data.bin",
    epochs=15,
    batch_size=32,
    learning_rate=3e-4,
    use_ema=True,
    early_stopping=True
)

# 初始化模型
lm_config = LMConfig()
model = Transformer(lm_config)

# 加载数据
train_dataset = PretrainDataset(...)
val_dataset = PretrainDataset(...)

# 创建训练器
trainer = Trainer(config)
trainer.setup_model(model)
trainer.setup_optimizer()
trainer.setup_dataloaders(train_dataset, val_dataset)

# 开始训练
trainer.train()
```

#### 推理示例

```python
from optimized_inference import TextGenerator, GenerationConfig
from transformers import AutoTokenizer
import torch

# 加载模型
model = Transformer(lm_config)
model.load_state_dict(torch.load('out/pretrain_512.pth'))

# 加载分词器
tokenizer = AutoTokenizer.from_pretrained('/path/to/tokenizer')

# 创建生成器
generator = TextGenerator(model, tokenizer)

# 生成配置
gen_config = GenerationConfig(
    temperature=0.8,
    top_k=50,
    top_p=0.9,
    max_new_tokens=100
)

# 生成文本
result = generator.generate("中国", gen_config)
print(result)
```

---

## 🎯 主要优化点

### 1. 数据处理优化 ✅

- **合并清洗和预处理**: 一次性完成数据验证和清洗
- **断点续传**: 支持从中断处继续处理
- **数据统计**: 自动生成详细的数据统计信息
- **进度显示**: 实时显示处理进度
- **错误处理**: 更好的异常处理和日志记录

**示例：**
```python
processor = OptimizedDataProcessor(
    tokenizer_path='/path/to/tokenizer',
    max_length=512,
    chunk_size=50000
)

# 一键清洗和处理
processor.validate_and_clean_jsonl(input_path, output_path)
processor.process_dataset(input_path, output_path, resume=True)
processor.save_statistics('stats.json')
```

### 2. 训练优化 ✅

- **多种优化器**: AdamW (推荐), Adam
- **灵活的学习率调度**: Cosine (推荐), Linear, Polynomial
- **模型 EMA**: 提升生成质量
- **验证集和早停**: 防止过拟合
- **检查点管理**: 自动保存和恢复
- **Wandb 集成**: 实时监控训练
- **分布式训练**: 多GPU训练支持
- **混合精度训练**: 加速训练并节省显存

**主要参数：**
```bash
--optimizer_type adamw          # 优化器
--lr_scheduler cosine           # 学习率调度
--use_ema                       # 启用 EMA
--early_stopping                # 启用早停
--dtype bfloat16               # 混合精度
--accumulation_steps 4         # 梯度累积
--ddp                          # 分布式训练
```

### 3. 推理优化 ✅

- **多种采样策略**: 
  - Greedy (贪心)
  - Top-K
  - Top-P (Nucleus)
  - Temperature
  
- **生成控制**:
  - 重复惩罚
  - 长度惩罚
  - N-gram 阻止
  
- **性能优化**:
  - KV Cache 加速
  - 批量生成
  - 流式输出
  
- **使用场景**:
  - 单次生成
  - 交互式对话
  - 批量生成

**采样示例：**
```bash
# 创意写作（更随机）
--temperature 1.0 --top_k 50 --top_p 0.95

# 日常对话（平衡）
--temperature 0.8 --top_k 40 --top_p 0.9

# 事实回答（更确定）
--temperature 0.5 --greedy
```

### 4. 代码质量优化 ✅

- **清晰的代码结构**: 模块化设计
- **详细的注释**: 每个函数都有说明
- **配置文件支持**: YAML/JSON 配置
- **错误处理**: 完善的异常处理
- **易于扩展**: 面向对象设计

---

## 📊 性能对比

| 特性 | 原始版本 | 优化版本 |
|------|----------|----------|
| 数据处理 | 基础功能 | ✅ 断点续传 + 统计 |
| 优化器选择 | Adam | ✅ AdamW/Adam 可选 |
| 学习率调度 | 手动实现 | ✅ 多种策略 |
| EMA | ❌ 不支持 | ✅ 支持 |
| 早停 | ❌ 不支持 | ✅ 支持 |
| 检查点管理 | 基础 | ✅ 完善的管理 |
| 采样策略 | Greedy | ✅ Top-K/Top-P/Temperature |
| 批量生成 | ❌ 不支持 | ✅ 支持 |
| 流式输出 | ❌ 不支持 | ✅ 支持 |
| 配置管理 | 命令行参数 | ✅ YAML/JSON 配置 |
| 日志记录 | 简单 | ✅ 详细 + Wandb |

---

## 🔧 常见使用场景

### 场景 1: 首次训练

```bash
# 1. 处理数据
python optimized_data_processing.py

# 2. 修改配置文件 config.yaml
# 3. 开始训练
python train.py --config config.yaml --use_wandb

# 4. 测试模型
python inference.py --model_path out/best_model.pth --interactive
```

### 场景 2: 恢复训练

```bash
python train.py \
    --resume \
    --resume_from out/checkpoint_step_5000.pth
```

### 场景 3: 多GPU训练

```bash
torchrun --nproc_per_node=4 train.py \
    --config config.yaml \
    --ddp \
    --dtype bfloat16
```

### 场景 4: 显存不足

```bash
python train.py \
    --batch_size 8 \
    --accumulation_steps 4 \
    --dtype float16
```

### 场景 5: 批量推理

```bash
# 1. 准备提示文件 prompts.txt
# 2. 运行批量生成
python inference.py \
    --model_path out/best_model.pth \
    --batch_file prompts.txt
```

---

## 📝 重要提示

### ⚠️ 使用前准备

1. **确保模型代码存在**：需要在 `model/` 目录下提供：
   - `model.py` - Transformer 模型
   - `LMConfig.py` - 模型配置
   - `dataset.py` - 数据集类

2. **修改路径配置**：
   - 在 `config.yaml` 中修改分词器路径
   - 修改数据路径
   - 修改输出路径

3. **安装依赖**：
```bash
pip install torch transformers datasets jsonlines tqdm pyyaml numpy
```

### 💡 最佳实践

1. **训练前**：
   - 先用小数据集测试
   - 检查数据统计信息
   - 设置合理的验证集

2. **训练时**：
   - 使用 Wandb 监控
   - 定期检查验证损失
   - 保存多个检查点

3. **推理时**：
   - 先用默认参数测试
   - 根据效果调整采样参数
   - 使用批量生成提高效率

---

## 📚 更多信息

- **详细文档**: 查看 `README_优化版使用说明.md`
- **代码示例**: 运行 `python quick_start.py`
- **配置说明**: 查看 `config.yaml` 中的注释

---

## 🎉 开始使用

选择您喜欢的方式开始：

```bash
# 交互式演示
python quick_start.py

# 直接训练
python train.py --config config.yaml

# 直接推理
python inference.py --model_path out/pretrain_512.pth --interactive
```

祝您使用愉快！🚀

