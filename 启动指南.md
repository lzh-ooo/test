# ğŸš€ MateConv é¢„è®­ç»ƒä¼˜åŒ–ç‰ˆ - å¿«é€Ÿå¯åŠ¨æŒ‡å—

## ğŸ“ æ–‡ä»¶æ¸…å•

æˆ‘å·²ç»ä¸ºæ‚¨åˆ›å»ºäº†ä»¥ä¸‹ä¼˜åŒ–æ–‡ä»¶ï¼š

| æ–‡ä»¶å | è¯´æ˜ | ç”¨é€” |
|--------|------|------|
| `optimized_data_processing.py` | ä¼˜åŒ–çš„æ•°æ®å¤„ç†è„šæœ¬ | æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç† |
| `optimized_pretrain.py` | ä¼˜åŒ–çš„è®­ç»ƒæ¡†æ¶ | æ ¸å¿ƒè®­ç»ƒé€»è¾‘ |
| `optimized_inference.py` | ä¼˜åŒ–çš„æ¨ç†æ¡†æ¶ | æ–‡æœ¬ç”ŸæˆåŠŸèƒ½ |
| `train.py` | è®­ç»ƒå¯åŠ¨è„šæœ¬ | å¯åŠ¨è®­ç»ƒ |
| `inference.py` | æ¨ç†å¯åŠ¨è„šæœ¬ | å¯åŠ¨æ¨ç† |
| `utils.py` | å·¥å…·å‡½æ•° | è¾…åŠ©åŠŸèƒ½ |
| `config.yaml` | é…ç½®æ–‡ä»¶ | ç»Ÿä¸€é…ç½®ç®¡ç† |
| `quick_start.py` | å¿«é€Ÿå¯åŠ¨æ¼”ç¤º | äº¤äº’å¼æ¼”ç¤º |
| `README_ä¼˜åŒ–ç‰ˆä½¿ç”¨è¯´æ˜.md` | è¯¦ç»†ä½¿ç”¨æ–‡æ¡£ | å®Œæ•´è¯´æ˜ |
| `prompts_example.txt` | æ‰¹é‡æç¤ºç¤ºä¾‹ | æ‰¹é‡ç”Ÿæˆæµ‹è¯• |

---

## âš¡ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šå‘½ä»¤è¡Œå¯åŠ¨ï¼ˆæ¨èï¼‰

#### 1ï¸âƒ£ æ•°æ®å¤„ç†

```bash
python optimized_data_processing.py
```

#### 2ï¸âƒ£ æ¨¡å‹è®­ç»ƒ

**ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰ï¼š**
```bash
python train.py --config config.yaml
```

**ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼š**
```bash
python train.py \
    --epochs 15 \
    --batch_size 32 \
    --learning_rate 3e-4 \
    --optimizer_type adamw \
    --lr_scheduler cosine \
    --use_ema \
    --early_stopping
```

**åˆ†å¸ƒå¼è®­ç»ƒï¼ˆå¤šGPUï¼‰ï¼š**
```bash
torchrun --nproc_per_node=2 train.py --config config.yaml --ddp
```

#### 3ï¸âƒ£ æ¨¡å‹æ¨ç†

**å•æ¬¡ç”Ÿæˆï¼š**
```bash
python inference.py \
    --model_path out/pretrain_512.pth \
    --prompt "ä¸­å›½" \
    --temperature 0.8
```

**äº¤äº’å¼å¯¹è¯ï¼š**
```bash
python inference.py \
    --model_path out/pretrain_512.pth \
    --interactive
```

**æµå¼è¾“å‡ºï¼š**
```bash
python inference.py \
    --model_path out/pretrain_512.pth \
    --prompt "é•¿æ±Ÿã€" \
    --stream
```

**æ‰¹é‡ç”Ÿæˆï¼š**
```bash
python inference.py \
    --model_path out/pretrain_512.pth \
    --batch_file prompts_example.txt
```

---

### æ–¹å¼äºŒï¼šäº¤äº’å¼æ¼”ç¤º

```bash
python quick_start.py
```

è¿™ä¼šæ‰“å¼€ä¸€ä¸ªäº¤äº’å¼èœå•ï¼Œæ‚¨å¯ä»¥é€‰æ‹©è¦æ¼”ç¤ºçš„åŠŸèƒ½ã€‚

---

### æ–¹å¼ä¸‰ï¼šPython API

#### è®­ç»ƒç¤ºä¾‹

```python
from optimized_pretrain import Trainer, TrainingConfig
from model.model import Transformer
from model.LMConfig import LMConfig
from model.dataset import PretrainDataset

# åˆ›å»ºé…ç½®
config = TrainingConfig(
    data_path="./dataset/pretrain_data.bin",
    epochs=15,
    batch_size=32,
    learning_rate=3e-4,
    use_ema=True,
    early_stopping=True
)

# åˆå§‹åŒ–æ¨¡å‹
lm_config = LMConfig()
model = Transformer(lm_config)

# åŠ è½½æ•°æ®
train_dataset = PretrainDataset(...)
val_dataset = PretrainDataset(...)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = Trainer(config)
trainer.setup_model(model)
trainer.setup_optimizer()
trainer.setup_dataloaders(train_dataset, val_dataset)

# å¼€å§‹è®­ç»ƒ
trainer.train()
```

#### æ¨ç†ç¤ºä¾‹

```python
from optimized_inference import TextGenerator, GenerationConfig
from transformers import AutoTokenizer
import torch

# åŠ è½½æ¨¡å‹
model = Transformer(lm_config)
model.load_state_dict(torch.load('out/pretrain_512.pth'))

# åŠ è½½åˆ†è¯å™¨
tokenizer = AutoTokenizer.from_pretrained('/path/to/tokenizer')

# åˆ›å»ºç”Ÿæˆå™¨
generator = TextGenerator(model, tokenizer)

# ç”Ÿæˆé…ç½®
gen_config = GenerationConfig(
    temperature=0.8,
    top_k=50,
    top_p=0.9,
    max_new_tokens=100
)

# ç”Ÿæˆæ–‡æœ¬
result = generator.generate("ä¸­å›½", gen_config)
print(result)
```

---

## ğŸ¯ ä¸»è¦ä¼˜åŒ–ç‚¹

### 1. æ•°æ®å¤„ç†ä¼˜åŒ– âœ…

- **åˆå¹¶æ¸…æ´—å’Œé¢„å¤„ç†**: ä¸€æ¬¡æ€§å®Œæˆæ•°æ®éªŒè¯å’Œæ¸…æ´—
- **æ–­ç‚¹ç»­ä¼ **: æ”¯æŒä»ä¸­æ–­å¤„ç»§ç»­å¤„ç†
- **æ•°æ®ç»Ÿè®¡**: è‡ªåŠ¨ç”Ÿæˆè¯¦ç»†çš„æ•°æ®ç»Ÿè®¡ä¿¡æ¯
- **è¿›åº¦æ˜¾ç¤º**: å®æ—¶æ˜¾ç¤ºå¤„ç†è¿›åº¦
- **é”™è¯¯å¤„ç†**: æ›´å¥½çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•

**ç¤ºä¾‹ï¼š**
```python
processor = OptimizedDataProcessor(
    tokenizer_path='/path/to/tokenizer',
    max_length=512,
    chunk_size=50000
)

# ä¸€é”®æ¸…æ´—å’Œå¤„ç†
processor.validate_and_clean_jsonl(input_path, output_path)
processor.process_dataset(input_path, output_path, resume=True)
processor.save_statistics('stats.json')
```

### 2. è®­ç»ƒä¼˜åŒ– âœ…

- **å¤šç§ä¼˜åŒ–å™¨**: AdamW (æ¨è), Adam
- **çµæ´»çš„å­¦ä¹ ç‡è°ƒåº¦**: Cosine (æ¨è), Linear, Polynomial
- **æ¨¡å‹ EMA**: æå‡ç”Ÿæˆè´¨é‡
- **éªŒè¯é›†å’Œæ—©åœ**: é˜²æ­¢è¿‡æ‹Ÿåˆ
- **æ£€æŸ¥ç‚¹ç®¡ç†**: è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤
- **Wandb é›†æˆ**: å®æ—¶ç›‘æ§è®­ç»ƒ
- **åˆ†å¸ƒå¼è®­ç»ƒ**: å¤šGPUè®­ç»ƒæ”¯æŒ
- **æ··åˆç²¾åº¦è®­ç»ƒ**: åŠ é€Ÿè®­ç»ƒå¹¶èŠ‚çœæ˜¾å­˜

**ä¸»è¦å‚æ•°ï¼š**
```bash
--optimizer_type adamw          # ä¼˜åŒ–å™¨
--lr_scheduler cosine           # å­¦ä¹ ç‡è°ƒåº¦
--use_ema                       # å¯ç”¨ EMA
--early_stopping                # å¯ç”¨æ—©åœ
--dtype bfloat16               # æ··åˆç²¾åº¦
--accumulation_steps 4         # æ¢¯åº¦ç´¯ç§¯
--ddp                          # åˆ†å¸ƒå¼è®­ç»ƒ
```

### 3. æ¨ç†ä¼˜åŒ– âœ…

- **å¤šç§é‡‡æ ·ç­–ç•¥**: 
  - Greedy (è´ªå¿ƒ)
  - Top-K
  - Top-P (Nucleus)
  - Temperature
  
- **ç”Ÿæˆæ§åˆ¶**:
  - é‡å¤æƒ©ç½š
  - é•¿åº¦æƒ©ç½š
  - N-gram é˜»æ­¢
  
- **æ€§èƒ½ä¼˜åŒ–**:
  - KV Cache åŠ é€Ÿ
  - æ‰¹é‡ç”Ÿæˆ
  - æµå¼è¾“å‡º
  
- **ä½¿ç”¨åœºæ™¯**:
  - å•æ¬¡ç”Ÿæˆ
  - äº¤äº’å¼å¯¹è¯
  - æ‰¹é‡ç”Ÿæˆ

**é‡‡æ ·ç¤ºä¾‹ï¼š**
```bash
# åˆ›æ„å†™ä½œï¼ˆæ›´éšæœºï¼‰
--temperature 1.0 --top_k 50 --top_p 0.95

# æ—¥å¸¸å¯¹è¯ï¼ˆå¹³è¡¡ï¼‰
--temperature 0.8 --top_k 40 --top_p 0.9

# äº‹å®å›ç­”ï¼ˆæ›´ç¡®å®šï¼‰
--temperature 0.5 --greedy
```

### 4. ä»£ç è´¨é‡ä¼˜åŒ– âœ…

- **æ¸…æ™°çš„ä»£ç ç»“æ„**: æ¨¡å—åŒ–è®¾è®¡
- **è¯¦ç»†çš„æ³¨é‡Š**: æ¯ä¸ªå‡½æ•°éƒ½æœ‰è¯´æ˜
- **é…ç½®æ–‡ä»¶æ”¯æŒ**: YAML/JSON é…ç½®
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†
- **æ˜“äºæ‰©å±•**: é¢å‘å¯¹è±¡è®¾è®¡

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç‰¹æ€§ | åŸå§‹ç‰ˆæœ¬ | ä¼˜åŒ–ç‰ˆæœ¬ |
|------|----------|----------|
| æ•°æ®å¤„ç† | åŸºç¡€åŠŸèƒ½ | âœ… æ–­ç‚¹ç»­ä¼  + ç»Ÿè®¡ |
| ä¼˜åŒ–å™¨é€‰æ‹© | Adam | âœ… AdamW/Adam å¯é€‰ |
| å­¦ä¹ ç‡è°ƒåº¦ | æ‰‹åŠ¨å®ç° | âœ… å¤šç§ç­–ç•¥ |
| EMA | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| æ—©åœ | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| æ£€æŸ¥ç‚¹ç®¡ç† | åŸºç¡€ | âœ… å®Œå–„çš„ç®¡ç† |
| é‡‡æ ·ç­–ç•¥ | Greedy | âœ… Top-K/Top-P/Temperature |
| æ‰¹é‡ç”Ÿæˆ | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| æµå¼è¾“å‡º | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| é…ç½®ç®¡ç† | å‘½ä»¤è¡Œå‚æ•° | âœ… YAML/JSON é…ç½® |
| æ—¥å¿—è®°å½• | ç®€å• | âœ… è¯¦ç»† + Wandb |

---

## ğŸ”§ å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: é¦–æ¬¡è®­ç»ƒ

```bash
# 1. å¤„ç†æ•°æ®
python optimized_data_processing.py

# 2. ä¿®æ”¹é…ç½®æ–‡ä»¶ config.yaml
# 3. å¼€å§‹è®­ç»ƒ
python train.py --config config.yaml --use_wandb

# 4. æµ‹è¯•æ¨¡å‹
python inference.py --model_path out/best_model.pth --interactive
```

### åœºæ™¯ 2: æ¢å¤è®­ç»ƒ

```bash
python train.py \
    --resume \
    --resume_from out/checkpoint_step_5000.pth
```

### åœºæ™¯ 3: å¤šGPUè®­ç»ƒ

```bash
torchrun --nproc_per_node=4 train.py \
    --config config.yaml \
    --ddp \
    --dtype bfloat16
```

### åœºæ™¯ 4: æ˜¾å­˜ä¸è¶³

```bash
python train.py \
    --batch_size 8 \
    --accumulation_steps 4 \
    --dtype float16
```

### åœºæ™¯ 5: æ‰¹é‡æ¨ç†

```bash
# 1. å‡†å¤‡æç¤ºæ–‡ä»¶ prompts.txt
# 2. è¿è¡Œæ‰¹é‡ç”Ÿæˆ
python inference.py \
    --model_path out/best_model.pth \
    --batch_file prompts.txt
```

---

## ğŸ“ é‡è¦æç¤º

### âš ï¸ ä½¿ç”¨å‰å‡†å¤‡

1. **ç¡®ä¿æ¨¡å‹ä»£ç å­˜åœ¨**ï¼šéœ€è¦åœ¨ `model/` ç›®å½•ä¸‹æä¾›ï¼š
   - `model.py` - Transformer æ¨¡å‹
   - `LMConfig.py` - æ¨¡å‹é…ç½®
   - `dataset.py` - æ•°æ®é›†ç±»

2. **ä¿®æ”¹è·¯å¾„é…ç½®**ï¼š
   - åœ¨ `config.yaml` ä¸­ä¿®æ”¹åˆ†è¯å™¨è·¯å¾„
   - ä¿®æ”¹æ•°æ®è·¯å¾„
   - ä¿®æ”¹è¾“å‡ºè·¯å¾„

3. **å®‰è£…ä¾èµ–**ï¼š
```bash
pip install torch transformers datasets jsonlines tqdm pyyaml numpy
```

### ğŸ’¡ æœ€ä½³å®è·µ

1. **è®­ç»ƒå‰**ï¼š
   - å…ˆç”¨å°æ•°æ®é›†æµ‹è¯•
   - æ£€æŸ¥æ•°æ®ç»Ÿè®¡ä¿¡æ¯
   - è®¾ç½®åˆç†çš„éªŒè¯é›†

2. **è®­ç»ƒæ—¶**ï¼š
   - ä½¿ç”¨ Wandb ç›‘æ§
   - å®šæœŸæ£€æŸ¥éªŒè¯æŸå¤±
   - ä¿å­˜å¤šä¸ªæ£€æŸ¥ç‚¹

3. **æ¨ç†æ—¶**ï¼š
   - å…ˆç”¨é»˜è®¤å‚æ•°æµ‹è¯•
   - æ ¹æ®æ•ˆæœè°ƒæ•´é‡‡æ ·å‚æ•°
   - ä½¿ç”¨æ‰¹é‡ç”Ÿæˆæé«˜æ•ˆç‡

---

## ğŸ“š æ›´å¤šä¿¡æ¯

- **è¯¦ç»†æ–‡æ¡£**: æŸ¥çœ‹ `README_ä¼˜åŒ–ç‰ˆä½¿ç”¨è¯´æ˜.md`
- **ä»£ç ç¤ºä¾‹**: è¿è¡Œ `python quick_start.py`
- **é…ç½®è¯´æ˜**: æŸ¥çœ‹ `config.yaml` ä¸­çš„æ³¨é‡Š

---

## ğŸ‰ å¼€å§‹ä½¿ç”¨

é€‰æ‹©æ‚¨å–œæ¬¢çš„æ–¹å¼å¼€å§‹ï¼š

```bash
# äº¤äº’å¼æ¼”ç¤º
python quick_start.py

# ç›´æ¥è®­ç»ƒ
python train.py --config config.yaml

# ç›´æ¥æ¨ç†
python inference.py --model_path out/pretrain_512.pth --interactive
```

ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸš€

